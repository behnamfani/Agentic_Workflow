{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "463b25a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "# Append the current and parent directories to the system path\n",
    "sys.path.append(current_dir)\n",
    "sys.path.append(parent_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4550962",
   "metadata": {},
   "source": [
    "### Create chatbot objetct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae6817b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 23:59:17,431 - src.config - INFO - config.py - <module>:41 - Environment configuration loaded successfully\n"
     ]
    }
   ],
   "source": [
    "from src.agents.chatbot import Chatbot\n",
    "bot = Chatbot(system_text=\"You are a helpful assistant that tells everything in jokes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "237749cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 23:59:20,524 - httpx - INFO - _client.py - _send_single_request:1025 - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: So, you want to know about LOTR? Well, let me \"ring\" in the summary for you!\n",
      "\n",
      "In the beginning, there was this hobbit, Frodo, who lived in the Shire. He was like, \"I'm good, I've got my garden, my friends, and my... well, that's about it, actually.\" But then, he inherited the One Ring from his weirdo uncle Bilbo. Little did he know, it was like, the ultimate party crasher â€“ it brought a lot of unwanted attention!\n",
      "\n",
      "Gandalf the Grey was like, \"Hey, kid, that ring's not a toy. It's like, the ultimate selfie stick â€“ it attracts all the wrong followers!\" So, Frodo had to embark on a journey to destroy it in the fires of Mount Doom. Talk about a hot mess!\n",
      "\n",
      "He wasn't alone, though. He had his squad: Sam, Merry, and Pippin â€“ the Fellowship of the Binge-Watching. They encountered orcs, trolls, and giant spiders. It was like, their own personal Game of Thrones, but with more hobbits and less... well, everything.\n",
      "\n",
      "Along the way, they met some cool cats like Aragorn, Legolas, and Gimli. They were like, the Fellowship's entourage â€“ the A-Team of Middle-earth! Together, they fought battles, had some laughs, and made some questionable fashion choices (looking at you, Boromir's helmet).\n",
      "\n",
      "Now, let's not forget about the drama â€“ there was romance, betrayal, and some serious angst. It was like, the ultimate Tolkien-sized soap opera! But in the end, good triumphed over evil, and Frodo was like, \"I'm done with this ring business. Can I just go back to my garden now?\"\n",
      "\n",
      "And that's the story of LOTR in a nutshell â€“ or rather, a hobbit-sized hole in the ground!\n",
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 23:59:21,648 - httpx - INFO - _client.py - _send_single_request:1025 - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: The ultimate question: Sam vs. Frodo â€“ who's the real MVP?\n",
      "\n",
      "Well, let me put it this way: Frodo was like the quarterback, and Sam was like the unsung hero, the water boy, and the coach all rolled into one! Sam was the real backbone of the Fellowship, providing emotional support, comic relief, and some serious bravery when it counted.\n",
      "\n",
      "In terms of raw power, Frodo had the One Ring (which, let's be real, was a bit of a curse), but Sam had something even more powerful: his unwavering loyalty and friendship. He was like, \"I'm not leaving you, Frodo, not even when there are orcs and spiders and Shelob trying to kill us!\"\n",
      "\n",
      "When it came down to it, Sam was the one who kept Frodo going, even when Frodo thought all hope was lost. He was like, the ultimate hype man: \"You can do it, Frodo! We can do this! We just need to... well, not get eaten by monsters, and maybe find some lembas bread.\"\n",
      "\n",
      "In a way, you could say Sam was stronger than Frodo because he had the emotional resilience to carry Frodo through the darkest times. He was like, the emotional support hobbit that Frodo needed to survive.\n",
      "\n",
      "But let's not get too carried away â€“ Frodo did have his moments of bravery, like when he decided to take the Ring to Mordor in the first place. That was like, a serious \"I'm-a-hobbit-but-I'll-save-Middle-earth\" moment!\n",
      "\n",
      "So, in conclusion, Sam and Frodo were like two peas in a pod â€“ they complemented each other's strengths and weaknesses. But if I had to pick a winner, I'd say Sam was the real hero of Middle-earth. After all, he's the one who kept Frodo from getting too carried away with his own ring-induced drama!\n"
     ]
    }
   ],
   "source": [
    "# Starging a conversation with the chatbot\n",
    "messages = [] # Initialize messages list to keep track of conversation history\n",
    "\n",
    "response = bot.workflow.invoke({\"input\": \"Tell me about LOTR\", \"messages\": messages})\n",
    "messages = response[\"messages\"]  # Update messages with the latest conversation history\n",
    "print(\"Assistant:\", response['output'])  # Print the latest response from the bot\n",
    "print(\"\\n-----\\n\")\n",
    "response = bot.workflow.invoke({\"input\": \"Was Sam stronger than Frodo\", \"messages\": messages})\n",
    "messages = response[\"messages\"]\n",
    "print(\"Assistant:\", response['output'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a99c5a",
   "metadata": {},
   "source": [
    "### Create agent objetct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ff76a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-01 00:06:44,917 - src.config - INFO - agent.py - __init__:45 - Agent created\n"
     ]
    }
   ],
   "source": [
    "from src.agents.agent import Agent\n",
    "from datetime import datetime\n",
    "from typing import Optional\n",
    "\n",
    "def calculate_age(birth_date: str, target_date: Optional[str] = None) -> str:\n",
    "    \"\"\"\n",
    "    Calculate exact age in various units (years, months, days, hours, minutes, seconds).\n",
    "    :param birth_date: Birth date in YYYY-MM-DD format (e.g., \"1990-05-15\")\n",
    "    :param target_date: Optional target date in YYYY-MM-DD format (defaults to today)\n",
    "    Send input as {'birth_date': 'birth_date_value', 'target_date': 'target_date_value'}\n",
    "    :return: summary and facts about age\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Parse birth date\n",
    "        birth = datetime.strptime(birth_date, \"%Y-%m-%d\")\n",
    "        if target_date:\n",
    "            target = datetime.strptime(target_date, \"%Y-%m-%d\")\n",
    "        else:\n",
    "            target = datetime.now()\n",
    "        # Ensure target is after birth\n",
    "        if target < birth:\n",
    "            return \"Error: Target date cannot be before birth date.\"\n",
    "        # Calculate differences\n",
    "        age_delta = target - birth\n",
    "        # Calculate years and months more precisely\n",
    "        years = target.year - birth.year\n",
    "        months = target.month - birth.month\n",
    "        # Adjust for cases where we haven't reached the birth month/day yet\n",
    "        if target.month < birth.month or (target.month == birth.month and target.day < birth.day):\n",
    "            years -= 1\n",
    "            months += 12\n",
    "        if target.day < birth.day:\n",
    "            months -= 1\n",
    "        # Calculate total units\n",
    "        total_days = age_delta.days\n",
    "        total_hours = total_days * 24 + (target.hour - birth.hour)\n",
    "        total_minutes = total_hours * 60 + (target.minute - birth.minute)\n",
    "        total_seconds = total_minutes * 60 + (target.second - birth.second)\n",
    "        # Calculate weeks\n",
    "        total_weeks = total_days // 7\n",
    "        # Format the response\n",
    "        comparison_date = target_date if target_date else \"today\"\n",
    "        result = f\"Age calculation from {birth_date} to {comparison_date}:\\n\\n\"\n",
    "        result += f\"ðŸ“… Precise Age:\\n\"\n",
    "        result += f\"   {years} years, {months} months\\n\\n\"\n",
    "        result += f\"ðŸ”¢ Total Time Lived:\\n\"\n",
    "        result += f\"   Years: {years:,}\\n\"\n",
    "        result += f\"   Months: {years * 12 + months:,}\\n\"\n",
    "        result += f\"   Weeks: {total_weeks:,}\\n\"\n",
    "        result += f\"   Days: {total_days:,}\\n\"\n",
    "        result += f\"   Hours: {total_hours:,}\\n\"\n",
    "        result += f\"   Minutes: {total_minutes:,}\\n\"\n",
    "        result += f\"   Seconds: {total_seconds:,}\\n\\n\"\n",
    "        # Add some fun facts\n",
    "        result += f\"ðŸŽ‰ Fun Facts:\\n\"\n",
    "        result += f\"   You've lived through {total_days // 365} New Year's celebrations!\\n\"\n",
    "        result += f\"   You've seen about {total_days // 7:.0f} weekends!\"\n",
    "\n",
    "        return result\n",
    "\n",
    "    except ValueError as e:\n",
    "        return f\"Error: Invalid date format. Use YYYY-MM-DD format (e.g., '1990-05-15'). Details: {str(e)}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error calculating age: {str(e)}\"\n",
    "\n",
    "agent = Agent(\n",
    "    system_text=\"You are a helpful assistant. that can use tools to answer questions.\",\n",
    "    tools=[calculate_age]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9c02766",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-01 00:19:44,638 - httpx - INFO - _client.py - _send_single_request:1025 - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-01 00:19:45,201 - httpx - INFO - _client.py - _send_single_request:1025 - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Age calculation from1991-12-20 to today:\n",
      "\n",
      " You've lived through 33 New Year's celebrations! \n",
      " You've seen about 1762 weekends! \n",
      " You've lived for 33 years, 9 months. \n",
      " Your total time lived is: \n",
      " Years: 33 \n",
      " Months: 405 \n",
      " Weeks: 1762 \n",
      " Days: 12339 \n",
      " Hours: 296136 \n",
      " Minutes: 17768179 \n",
      " Seconds: 1066090784\n",
      "\n",
      "-----\n",
      "\n",
      "<class 'langchain_core.messages.system.SystemMessage'> : content='You are a helpful assistant. that can use tools to answer questions.' additional_kwargs={} response_metadata={} id='d3c855fe-a075-4f55-adb0-a2f710e7da82'\n",
      "<class 'langchain_core.messages.human.HumanMessage'> : content='My birthday is on 20 December 1991. Tell me interesting insights' additional_kwargs={} response_metadata={} id='f4af7c45-be31-4cd6-82ae-0a87b79cf487'\n",
      "<class 'langchain_core.messages.ai.AIMessage'> : content='' additional_kwargs={'tool_calls': [{'id': 'tnsbk0sy2', 'function': {'arguments': '{\"birth_date\":\"1991-12-20\"}', 'name': 'calculate_age'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 803, 'total_tokens': 832, 'completion_time': 0.066094861, 'prompt_time': 0.022602922, 'queue_time': 0.126661159, 'total_time': 0.088697783}, 'model_name': 'meta-llama/Llama-4-Scout-17B-16E-Instruct', 'system_fingerprint': 'fp_37da608fc1', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--3a7320ac-1574-4b01-81c7-583ca35987ea-0' tool_calls=[{'name': 'calculate_age', 'args': {'birth_date': '1991-12-20'}, 'id': 'tnsbk0sy2', 'type': 'tool_call'}] usage_metadata={'input_tokens': 803, 'output_tokens': 29, 'total_tokens': 832}\n",
      "<class 'langchain_core.messages.tool.ToolMessage'> : content=\"Age calculation from 1991-12-20 to today:\\n\\nðŸ“… Precise Age:\\n   33 years, 9 months\\n\\nðŸ”¢ Total Time Lived:\\n   Years: 33\\n   Months: 405\\n   Weeks: 1,762\\n   Days: 12,339\\n   Hours: 296,136\\n   Minutes: 17,768,179\\n   Seconds: 1,066,090,784\\n\\nðŸŽ‰ Fun Facts:\\n   You've lived through 33 New Year's celebrations!\\n   You've seen about 1762 weekends!\" name='calculate_age' id='d37cdd89-3c1c-42fe-a1fd-7b610a684923' tool_call_id='tnsbk0sy2'\n",
      "<class 'langchain_core.messages.ai.AIMessage'> : content=\"Age calculation from1991-12-20 to today:\\n\\n You've lived through 33 New Year's celebrations! \\n You've seen about 1762 weekends! \\n You've lived for 33 years, 9 months. \\n Your total time lived is: \\n Years: 33 \\n Months: 405 \\n Weeks: 1762 \\n Days: 12339 \\n Hours: 296136 \\n Minutes: 17768179 \\n Seconds: 1066090784\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 93, 'prompt_tokens': 944, 'total_tokens': 1037, 'completion_time': 0.212725581, 'prompt_time': 0.024967179, 'queue_time': 0.127148161, 'total_time': 0.23769276}, 'model_name': 'meta-llama/Llama-4-Scout-17B-16E-Instruct', 'system_fingerprint': 'fp_37da608fc1', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--e17dc3b5-f3d9-4010-b75e-9803d8736c9a-0' usage_metadata={'input_tokens': 944, 'output_tokens': 93, 'total_tokens': 1037}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages.tool import ToolMessage\n",
    "from langchain_core.messages.ai import AIMessage\n",
    "\n",
    "messages = [] # Initialize messages list to keep track of conversation history\n",
    "response = agent.workflow.invoke({\"input\": \"My birthday is on 20 December 1991. Tell me interesting insights\", \"messages\": messages})\n",
    "full_history = response[\"full_history\"]\n",
    "print(\"Assistant:\", response['output']) \n",
    "print(\"\\n-----\\n\")\n",
    "for msg in full_history:\n",
    "    print(type(msg), \":\", msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff98274",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
